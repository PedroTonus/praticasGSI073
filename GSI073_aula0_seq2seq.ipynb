{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroTonus/praticasGSI073/blob/main/GSI073_aula0_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação dos dados\n",
        "\n",
        "Esta tarefa é inverter sequências de caracteres. Exemplo: **aabcd** em **dcbaa**.\n"
      ],
      "metadata": {
        "id": "o8ZBsZcshFv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "chars = list(\"abcd \")\n",
        "vocab = {ch: i for i, ch in enumerate(chars)} # Cada letra, ganha um número\n",
        "inv_vocab = {i: ch for ch, i in vocab.items()}# Tabela de decodificação\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "def encode(s): # Codifica letras em números\n",
        "    return torch.tensor([vocab[c] for c in s], dtype=torch.long)\n",
        "\n",
        "def decode(t): # Decodifica números em letras\n",
        "    return ''.join(inv_vocab[int(x)] for x in t)\n",
        "\n",
        "def random_seq(n=5): # Cria novas sequências\n",
        "    return ''.join(random.choice(chars[:-1]) for _ in range(n))\n",
        "\n",
        "# Gerar dados\n",
        "pairs = [(encode(s), encode(s[::-1])) for s in [random_seq() for _ in range(50000)]]\n",
        "\n",
        "max_len = max(len(x) for x, _ in pairs) # pega maior sequência\n",
        "\n",
        "def pad(x):  # Preenche conjunto de dados em pad no último índice\n",
        "    return torch.cat([x, torch.tensor([vocab[' ']] * (max_len - len(x)))], dim=0)\n",
        "\n",
        "inputs = torch.stack([pad(x) for x, _ in pairs])\n",
        "targets = torch.stack([pad(y) for _, y in pairs])\n",
        "\n",
        "train_ds = torch.utils.data.TensorDataset(inputs, targets)\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "ylarIE4Wd0ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Veja um par"
      ],
      "metadata": {
        "id": "P43qdDKt59V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pairs[1])"
      ],
      "metadata": {
        "id": "H9GyPfjahI_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição do modelo Seq2Seq com GRU"
      ],
      "metadata": {
        "id": "A5ddkeXUhDBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, emb_size)\n",
        "        self.gru = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        _, h = self.gru(x)\n",
        "        return h  # [1, B, H]\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, emb_size)\n",
        "        self.gru = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        \"\"\"\n",
        "        x: tensor que indica a parte prévia correta\n",
        "        h: tensor que indica o estado do encoder da parte prévia\n",
        "        \"\"\"\n",
        "        x = self.embed(x)\n",
        "        out, h = self.gru(x, h)\n",
        "        logits = self.fc(out)\n",
        "        return logits, h # retorna o estado latente para atualizar o estado\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        h = self.encoder(src)\n",
        "        # usa contexto correto anterior e estado atual para prever o tgt[:, -1]\n",
        "        logits, _ = self.decoder(tgt[:, :-1], h)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "d-1LP2kIdh4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Código para usar o modelo treinado: inferência"
      ],
      "metadata": {
        "id": "o39huAV1soHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_step(decoder, token, h):\n",
        "    logits, h = decoder(token, h) # obtém logits e atualiza estado da sequência\n",
        "    next_token = logits[:, -1, :].argmax(-1, keepdim=True)\n",
        "    return next_token, h\n",
        "\n",
        "def predict(model, seq, max_len=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        src = pad(encode(seq)).unsqueeze(0).to(device, dtype=torch.long)\n",
        "        h = model.encoder(src) # Obtém estado do modelo após processar entrada inicial\n",
        "\n",
        "        # 'token' representa a geração passo a passo da sequência invertida\n",
        "        token = torch.tensor([[vocab[' ']]], dtype=torch.long, device=device)\n",
        "        seq_invertida = []\n",
        "        for _ in range(max_len):\n",
        "            token, h = decode_step(model.decoder, token, h)\n",
        "            seq_invertida.append(token.item())\n",
        "        return decode(seq_invertida)"
      ],
      "metadata": {
        "id": "x6MshjDHsnbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação para treino"
      ],
      "metadata": {
        "id": "qVzYCLNjg_ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_size = 32\n",
        "hidden_size = 64\n",
        "encoder = Encoder(vocab_size, emb_size, hidden_size)\n",
        "decoder = Decoder(vocab_size, emb_size, hidden_size)\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=vocab[' ']) # ignora o pad: \" \"\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "-abFA-NmeJzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execução do treino"
      ],
      "metadata": {
        "id": "JacyZGK940n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_dl:\n",
        "        xb, yb = xb.to(device, dtype=torch.long), yb.to(device, dtype=torch.long)\n",
        "        opt.zero_grad()\n",
        "        logits = model(xb, yb)\n",
        "        loss = loss_fn(logits.reshape(-1, vocab_size), yb[:, 1:].reshape(-1))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: loss={total_loss/len(train_dl):.4f}\")"
      ],
      "metadata": {
        "id": "rKl4t82iePsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vamos testar"
      ],
      "metadata": {
        "id": "-hnWdfoq4xL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    s = random_seq()\n",
        "    pred = predict(model, s, max_len=len(s))\n",
        "    print(f\"{s} -> {pred}\")\n"
      ],
      "metadata": {
        "id": "MDDLTV7CeVa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercício\n",
        "Compare o resultado do uso do encoder de de sequências muito similares e muito diferentes. Por exemplo, codifique \"aaaabb\", \"bbaaab\", \"cbcaccc\" e \"cccacbc\" e depois faça uma figura das 2 componentes principais usando o método Principal Components Analysis (PCA) do pacote `sklearn.decomposition.PCA`."
      ],
      "metadata": {
        "id": "-kSlkh5Tusfg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb5cb59e"
      },
      "source": [
        "# Task\n",
        "Compare the results of using the encoder on very similar and very different sequences. Specifically, encode the sequences \"aaaabb\", \"bbaaab\", \"cbcaccc\", and \"cccacbc\", then generate a figure showing their 2 principal components using the Principal Components Analysis (PCA) method from `sklearn.decomposition.PCA`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "056089c5"
      },
      "source": [
        "## Definir e Codificar Sequências\n",
        "\n",
        "### Subtask:\n",
        "Definir as sequências de entrada ('aaaabb', 'bbaaab', 'cbcaccc', 'cccacbc') e codificá-las usando a função `encode` existente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30b8f19f"
      },
      "source": [
        "**Reasoning**:\n",
        "I will create a list of the specified test sequences, then iterate through them to encode and pad each one using the existing `encode` and `pad` functions, storing the results in `encoded_padded_sequences`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ff5dd1a"
      },
      "source": [
        "test_sequences = ['aaaabb', 'bbaaab', 'cbcaccc', 'cccacbc']\n",
        "\n",
        "# Aumentar o max_len para acomodar as novas sequências, se necessário\n",
        "# Usar um max_len maior para garantir que todas as sequências de teste sejam padronizadas corretamente\n",
        "max_len_for_test = max(max_len, max(len(s) for s in test_sequences))\n",
        "\n",
        "def pad_for_test(x):  # Cria uma nova função pad que usa o max_len_for_test\n",
        "    return torch.cat([x, torch.tensor([vocab[' ']] * (max_len_for_test - len(x)))], dim=0)\n",
        "\n",
        "encoded_padded_sequences = [pad_for_test(encode(s)) for s in test_sequences]\n",
        "\n",
        "print(\"Test Sequences:\", test_sequences)\n",
        "print(\"Encoded and Padded Sequences:\", encoded_padded_sequences)\n",
        "print(\"Max length used for padding:\", max_len_for_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61ef85e6"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the test sequences are encoded and padded, the next step is to obtain the encoder outputs (embeddings) for these sequences using the trained model's encoder. These embeddings will then be used for PCA.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e2e6efc"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Empilhar os tensores e movê-los para o dispositivo correto\n",
        "    encoded_padded_sequences_tensor = torch.stack(encoded_padded_sequences).to(device, dtype=torch.long)\n",
        "    encoder_outputs = model.encoder(encoded_padded_sequences_tensor)\n",
        "\n",
        "# O output do encoder para GRU é [num_layers * num_directions, batch_size, hidden_size]\n",
        "# Como temos apenas 1 camada e 1 direção, é [1, batch_size, hidden_size]\n",
        "# Precisamos espremer a primeira dimensão para obter [batch_size, hidden_size]\n",
        "encoder_embeddings = encoder_outputs.squeeze(0).cpu().numpy()\n",
        "\n",
        "print(\"Encoder Embeddings Shape:\", encoder_embeddings.shape)\n",
        "print(\"First embedding (sample):\")\n",
        "print(encoder_embeddings[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75f661ce"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that we have the encoder embeddings, the next step is to apply Principal Component Analysis (PCA) to reduce their dimensionality to 2 components. This will allow for visualization of the sequence embeddings in a 2D space, helping to compare similar and different sequences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6134eeca"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize PCA with 2 components\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Fit PCA to the encoder embeddings and transform them\n",
        "pca_components = pca.fit_transform(encoder_embeddings)\n",
        "\n",
        "# Plot the 2 principal components\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i, (x, y) in enumerate(pca_components):\n",
        "    plt.scatter(x, y) # Plot the point\n",
        "    plt.annotate(test_sequences[i], (x, y), textcoords=\"offset points\", xytext=(5,5), ha='center') # Label with original sequence\n",
        "\n",
        "plt.title('PCA of Encoder Embeddings')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"PCA performed and plot generated.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce5f587b"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Analyze the PCA visualization and provide a comparative analysis of the sequence embeddings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efaf00d5"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The encoder successfully differentiated between \"very similar\" and \"very different\" sequences, as evidenced by the PCA visualization. Sequences \"aaaabb\" and \"bbaaab\" (which are very similar) are clustered together, and \"cbcaccc\" and \"cccacbc\" (also very similar) form another distinct cluster. These two clusters are clearly separated from each other in the 2-component PCA space, indicating that the encoder can distinguish between these two groups of sequences.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Four test sequences (`'aaaabb'`, `'bbaaab'`, `'cbcaccc'`, `'cccacbc'`) were successfully encoded and padded to a consistent length of 7 characters.\n",
        "*   The model's encoder generated 64-dimensional embeddings for each of the four sequences, resulting in an output shape of (4, 64).\n",
        "*   Principal Component Analysis (PCA) effectively reduced these 64-dimensional embeddings to 2 principal components, which were then plotted.\n",
        "*   The PCA plot visually demonstrates that the encoder groups similar sequences: \"aaaabb\" and \"bbaaab\" are located close to each other, and \"cbcaccc\" and \"cccacbc\" are also close to each other, forming a distinct cluster from the first pair.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The PCA visualization confirms that the encoder is effective at capturing semantic similarity between sequences, grouping closely related sequences while separating distinct ones.\n",
        "*   This approach can be utilized to quickly assess the learned representations of new sequences, aiding in tasks like anomaly detection or cluster analysis of sequence data.\n"
      ]
    }
  ]
}